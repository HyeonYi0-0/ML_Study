{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPdTDNzBYQu/qH3Q4mooGV3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# The Image Classification Dataset"],"metadata":{"id":"l03TdTQFl0ly"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s_FMn0iXlynR"},"outputs":[],"source":["%matplotlib inline\n","import time\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from d2l import torch as d2l\n","\n","d2l.use_svg_display()"]},{"cell_type":"code","source":["class FashionMNIST(d2l.DataModule):\n","    def __init__(self, batch_size=64, resize=(28, 28)):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        trans = transforms.Compose([transforms.Resize(resize),\n","                                    transforms.ToTensor()])\n","        self.train = torchvision.datasets.FashionMNIST(\n","            root=self.root, train=True, transform=trans, download=True)\n","        self.val = torchvision.datasets.FashionMNIST(\n","            root=self.root, train=False, transform=trans, download=True)"],"metadata":{"id":"nMZg2Ttjl78G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = FashionMNIST(resize=(32, 32))\n","len(data.train), len(data.val) #(60000, 10000)"],"metadata":{"id":"Q2oVHNROl-XK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.train[0][0].shape #torch.Size([1, 32, 32])"],"metadata":{"id":"ME9x6OUjmAFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@d2l.add_to_class(FashionMNIST)\n","def text_labels(self, indices):\n","    \"\"\"Return text labels.\"\"\"\n","    labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n","              'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n","    return [labels[int(i)] for i in indices]"],"metadata":{"id":"XvoPG7nzmFgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@d2l.add_to_class(FashionMNIST) \n","def get_dataloader(self, train):\n","    data = self.train if train else self.val\n","    return torch.utils.data.DataLoader(data, self.batch_size, shuffle=train,\n","                                       num_workers=self.num_workers)"],"metadata":{"id":"3kWs0r0omFmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X, y = next(iter(data.train_dataloader()))\n","print(X.shape, X.dtype, y.shape, y.dtype)\n","\n","#torch.Size([64, 1, 32, 32]) torch.float32 torch.Size([64]) torch.int64"],"metadata":{"id":"kBuaJZPUmKtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n","    raise NotImplementedError\n","\n","@d2l.add_to_class(FashionMNIST)\n","def visualize(self, batch, nrows=1, ncols=8, labels=[]):\n","    X, y = batch\n","    if not labels:\n","        labels = self.text_labels(y)\n","    d2l.show_images(X.squeeze(1), nrows, ncols, titles=labels)\n","batch = next(iter(data.val_dataloader()))\n","data.visualize(batch)"],"metadata":{"id":"uSccJdhomR4p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The Base Classification Model"],"metadata":{"id":"PBmlWhvUmd8P"}},{"cell_type":"code","source":["import torch\n","from d2l import torch as d2l"],"metadata":{"id":"JPmhISp_mfY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Classifier(d2l.Module):  \n","    def validation_step(self, batch):\n","        Y_hat = self(*batch[:-1])\n","        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n","        self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)\n","\n","@d2l.add_to_class(d2l.Module)\n","def configure_optimizers(self):\n","    return torch.optim.SGD(self.parameters(), lr=self.lr)\n","\n","@d2l.add_to_class(Classifier)\n","def accuracy(self, Y_hat, Y, averaged=True):\n","    \"\"\"Compute the number of correct predictions.\"\"\"\n","    Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n","    preds = Y_hat.argmax(axis=1).type(Y.dtype)\n","    compare = (preds == Y.reshape(-1)).type(torch.float32)\n","    return compare.mean() if averaged else compare"],"metadata":{"id":"o5eZxMAumg-w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Softmax Regression Implementation from Scratch"],"metadata":{"id":"VPG1Fj5imqul"}},{"cell_type":"code","source":["X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n","X.sum(0, keepdims=True), X.sum(1, keepdims=True)\n","\n","def softmax(X):\n","    X_exp = torch.exp(X)\n","    partition = X_exp.sum(1, keepdims=True)\n","    return X_exp / partition \n","\n","X = torch.rand((2, 5))\n","X_prob = softmax(X)\n","X_prob, X_prob.sum(1)\n","\n","# (tensor([[0.1560, 0.2128, 0.2260, 0.2372, 0.1680],\n","#          [0.1504, 0.2473, 0.1132, 0.2779, 0.2112]]),\n","#  tensor([1.0000, 1.0000]))"],"metadata":{"id":"WhdkxatPm0PT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SoftmaxRegressionScratch(d2l.Classifier):\n","    def __init__(self, num_inputs, num_outputs, lr, sigma=0.01):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.W = torch.normal(0, sigma, size=(num_inputs, num_outputs),\n","                              requires_grad=True)\n","        self.b = torch.zeros(num_outputs, requires_grad=True)\n","\n","    def parameters(self):\n","        return [self.W, self.b]\n","\n","@d2l.add_to_class(SoftmaxRegressionScratch)\n","def forward(self, X):\n","    X = X.reshape((-1, self.W.shape[0]))\n","    return softmax(torch.matmul(X, self.W) + self.b)"],"metadata":{"id":"ArZcy-kzm9jq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = torch.tensor([0, 2])\n","y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n","y_hat[[0, 1], y]\n","\n","# tensor([0.1000, 0.5000])"],"metadata":{"id":"xI1VSUkanEUA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cross_entropy(y_hat, y):\n","    return -torch.log(y_hat[list(range(len(y_hat))), y]).mean()\n","\n","cross_entropy(y_hat, y)\n","\n","# tensor(1.4979)\n","\n","@d2l.add_to_class(SoftmaxRegressionScratch)\n","def loss(self, y_hat, y):\n","    return cross_entropy(y_hat, y)"],"metadata":{"id":"70dho34DnHYs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = d2l.FashionMNIST(batch_size=256)\n","model = SoftmaxRegressionScratch(num_inputs=784, num_outputs=10, lr=0.1)\n","trainer = d2l.Trainer(max_epochs=10)\n","trainer.fit(model, data)"],"metadata":{"id":"q6NDUWl2nM_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X, y = next(iter(data.val_dataloader()))\n","preds = model(X).argmax(axis=1)\n","preds.shape\n","\n","wrong = preds.type(y.dtype) != y\n","X, y, preds = X[wrong], y[wrong], preds[wrong]\n","labels = [a+'\\n'+b for a, b in zip(\n","    data.text_labels(y), data.text_labels(preds))]\n","data.visualize([X, y], labels=labels)"],"metadata":{"id":"gqf8LSTvnQJC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Concise Implementation of Softmax Regression"],"metadata":{"id":"3uAlbD88nhIi"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from d2l import torch as d2l"],"metadata":{"id":"TEHRgIjfnlaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SoftmaxRegression(d2l.Classifier): \n","    def __init__(self, num_outputs, lr):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.net = nn.Sequential(nn.Flatten(),\n","                                 nn.LazyLinear(num_outputs))\n","\n","    def forward(self, X):\n","        return self.net(X)\n","\n","@d2l.add_to_class(d2l.Classifier)  \n","def loss(self, Y_hat, Y, averaged=True):\n","    Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n","    Y = Y.reshape((-1,))\n","    return F.cross_entropy(\n","        Y_hat, Y, reduction='mean' if averaged else 'none')"],"metadata":{"id":"rW5_QDKCnnSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = d2l.FashionMNIST(batch_size=256)\n","model = SoftmaxRegression(num_outputs=10, lr=0.1)\n","trainer = d2l.Trainer(max_epochs=10)\n","trainer.fit(model, data)"],"metadata":{"id":"ofL8Z4eDnxGj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 새 섹션"],"metadata":{"id":"NvEjS17en0vz"}}]}