{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lLvo7Gpcqeu1",
        "ndIjWVV3rX8h",
        "KgkJ1woNrv4_",
        "YkFQc3rgsTrI",
        "1zW_lZTZs8xM"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutions for Images"
      ],
      "metadata": {
        "id": "lLvo7Gpcqeu1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLKEgHQxqbyA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d(X, K): \n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "    return Y\n",
        "\n",
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "corr2d(X, K)\n",
        "\n",
        "# tensor([[19., 25.],\n",
        "#         [37., 43.]])"
      ],
      "metadata": {
        "id": "pxrMAhIAqpcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return corr2d(x, self.weight) + self.bias"
      ],
      "metadata": {
        "id": "9LTjwx1fqw3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X\n",
        "\n",
        "# tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
        "#         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
        "#         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
        "#         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
        "#         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
        "#         [1., 1., 0., 0., 0., 0., 1., 1.]])\n",
        "\n",
        "K = torch.tensor([[1.0, -1.0]])\n",
        "Y = corr2d(X, K)\n",
        "Y\n",
        "# tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
        "#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
        "#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
        "#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
        "#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
        "#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])\n",
        "\n",
        "corr2d(X.t(), K)\n",
        "# tensor([[0., 0., 0., 0., 0.],\n",
        "#         [0., 0., 0., 0., 0.],\n",
        "#         [0., 0., 0., 0., 0.],\n",
        "#         [0., 0., 0., 0., 0.],\n",
        "#         [0., 0., 0., 0., 0.],\n",
        "#         [0., 0., 0., 0., 0.],\n",
        "#         [0., 0., 0., 0., 0.],\n",
        "#         [0., 0., 0., 0., 0.]])"
      ],
      "metadata": {
        "id": "WcXoBkuHqzpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "X = X.reshape((1, 1, 6, 8))\n",
        "Y = Y.reshape((1, 1, 6, 7))\n",
        "lr = 3e-2\n",
        "\n",
        "for i in range(10):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y) ** 2\n",
        "    conv2d.zero_grad()\n",
        "    l.sum().backward()\n",
        "\n",
        "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "    if (i + 1) % 2 == 0:\n",
        "        print(f'epoch {i + 1}, loss {l.sum():.3f}')\n",
        "\n",
        "# epoch 2, loss 6.453\n",
        "# epoch 4, loss 1.491\n",
        "# epoch 6, loss 0.418\n",
        "# epoch 8, loss 0.139\n",
        "# epoch 10, loss 0.051\n",
        "\n",
        "conv2d.weight.data.reshape((1, 2)) #tensor([[ 1.0112, -0.9661]])"
      ],
      "metadata": {
        "id": "aasRtVOIrHTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding and Stride"
      ],
      "metadata": {
        "id": "ndIjWVV3rX8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comp_conv2d(conv2d, X):\n",
        "\n",
        "    X = X.reshape((1, 1) + X.shape)\n",
        "    Y = conv2d(X)\n",
        "\n",
        "    return Y.reshape(Y.shape[2:])\n",
        "\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
        "X = torch.rand(size=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape\n",
        "\n",
        "# torch.Size([8, 8])\n",
        "\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
        "comp_conv2d(conv2d, X).shape #torch.Size([8, 8])"
      ],
      "metadata": {
        "id": "gR_P1eVArcl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
        "comp_conv2d(conv2d, X).shape #torch.Size([4, 4])\n",
        "\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape #torch.Size([2, 2])"
      ],
      "metadata": {
        "id": "qnjBypdkrn9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Input and Multiple Output Channels"
      ],
      "metadata": {
        "id": "KgkJ1woNrv4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in(X, K):\n",
        "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))\n",
        "\n",
        "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
        "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
        "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
        "\n",
        "corr2d_multi_in(X, K)\n",
        "\n",
        "# tensor([[ 56.,  72.],\n",
        "#         [104., 120.]])"
      ],
      "metadata": {
        "id": "ZTkqz7zjry0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out(X, K):\n",
        "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
        "\n",
        "K = torch.stack((K, K + 1, K + 2), 0)\n",
        "K.shape #torch.Size([3, 2, 2, 2])\n",
        "\n",
        "corr2d_multi_in_out(X, K)\n",
        "\n",
        "# tensor([[[ 56.,  72.],\n",
        "#          [104., 120.]],\n",
        "\n",
        "#         [[ 76., 100.],\n",
        "#          [148., 172.]],\n",
        "\n",
        "#         [[ 96., 128.],\n",
        "#          [192., 224.]]])"
      ],
      "metadata": {
        "id": "CVxq7tLQr8i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "    c_o = K.shape[0]\n",
        "    X = X.reshape((c_i, h * w))\n",
        "    K = K.reshape((c_o, c_i))\n",
        "\n",
        "    Y = torch.matmul(K, X)\n",
        "    return Y.reshape((c_o, h, w))\n",
        "\n",
        "X = torch.normal(0, 1, (3, 3, 3))\n",
        "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
      ],
      "metadata": {
        "id": "qy-N-qjGsG3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pooling"
      ],
      "metadata": {
        "id": "YkFQc3rgsTrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pool2d(X, pool_size, mode='max'):\n",
        "    p_h, p_w = pool_size\n",
        "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            if mode == 'max':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
        "            elif mode == 'avg':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
        "    return Y\n",
        "\n",
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "pool2d(X, (2, 2))\n",
        "\n",
        "# tensor([[4., 5.],\n",
        "#         [7., 8.]])\n",
        "\n",
        "pool2d(X, (2, 2), 'avg')\n",
        "\n",
        "# tensor([[2., 3.],\n",
        "#         [5., 6.]])"
      ],
      "metadata": {
        "id": "pwVeGe6JsVgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
        "pool2d = nn.MaxPool2d(3)\n",
        "pool2d(X) #tensor([[[[10.]]]])\n",
        "\n",
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)\n",
        "\n",
        "# tensor([[[[ 5.,  7.],\n",
        "#           [13., 15.]]]])\n",
        "\n",
        "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
        "pool2d(X)\n",
        "\n",
        "# tensor([[[[ 5.,  7.],\n",
        "#           [13., 15.]]]])"
      ],
      "metadata": {
        "id": "RX--HVWhsli5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.cat((X, X + 1), 1)\n",
        "\n",
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)\n",
        "\n",
        "# tensor([[[[ 5.,  7.],\n",
        "#           [13., 15.]],\n",
        "\n",
        "#          [[ 6.,  8.],\n",
        "#           [14., 16.]]]])"
      ],
      "metadata": {
        "id": "-sRMyPBuszDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (LeNet)"
      ],
      "metadata": {
        "id": "1zW_lZTZs8xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_cnn(module):  \n",
        "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(module.weight)\n",
        "\n",
        "class LeNet(d2l.Classifier):  \n",
        "\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(120), nn.Sigmoid(),\n",
        "            nn.LazyLinear(84), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))\n",
        "        \n",
        "@d2l.add_to_class(d2l.Classifier)  \n",
        "def layer_summary(self, X_shape):\n",
        "    X = torch.randn(*X_shape)\n",
        "    for layer in self.net:\n",
        "        X = layer(X)\n",
        "        print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
        "\n",
        "model = LeNet()\n",
        "model.layer_summary((1, 1, 28, 28))\n",
        "\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "model = LeNet(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "5JONTojgs-8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}